{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analytical Parameter Model Optimizer using Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from numpy.polynomial.hermite import hermgauss\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize DataFrame to store data for EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_parameters = ['step', 'uBA','sbA','uBB','sbB','pA','pb','pc', 'pm','umax','nl',\n",
    "                 'eLJ','uc','cost']\n",
    "df_params = pd.DataFrame(columns = tf_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedam_data = pd.read_csv(\"sampl4-oah-b7eqnosc.repl.cycle.totE.potE.temp.lambda.ebind.dat\",delim_whitespace=True, \n",
    "                          header=None,names=[\"replica\",\"cycle\",\"totE\",\n",
    "                                             \"potE\",\"temp\",\"Lambda\",\"ebind\"])\n",
    "\n",
    "#ulambda = pandas.read_csv(\"bcd-nabumetone.repl\",delim_whitespace=True, \n",
    "#                          header=None,names=[\"replica\",\"cycle\",\"totE\",\n",
    "#                          \"potE\",\"temp\",\"Lambda\",\"ebind\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedam_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kT = 1.986e-3*300.0 # [kcal/mol]\n",
    "beta = 1/kT\n",
    "bedam_data['u'] = bedam_data['ebind']*beta\n",
    "bedam_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedam_data['mask'] = np.logical_and(bedam_data['Lambda'] > 1.e-6, bedam_data['cycle'] > 100)\n",
    "bedam_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_data = bedam_data.loc[bedam_data['mask'] == True]\n",
    "rel_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_data['u'] = rel_data['u'].astype(np.float32)\n",
    "rel_data['Lambda'] = rel_data['Lambda'].astype(np.float32)\n",
    "rel_data['U'] = rel_data['u']-1.e6*beta # u-umax\n",
    "rel_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize parameters\n",
    "\n",
    "parameters that are being optimized are stored in a `tf.Variable`, those that are kept constant are stored as `tf.constant`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pb = 1.18e-4\n",
    "pc = 3.00e-2\n",
    "uc = 0.5\n",
    "params = {'UBA':tf.constant(-13.953*beta),\n",
    "          'SIGBA':tf.constant(1.906*beta),\n",
    "          'UBB':tf.constant(-2.334*beta),\n",
    "          'SIGBB':tf.constant(3.238*beta),\n",
    "          'PA':tf.constant(2.45e-4),\n",
    "          'E':tf.constant(20.0*beta),\n",
    "          'UC':tf.constant(uc*beta),\n",
    "          'NL':tf.Variable(2.96),\n",
    "          'PB':tf.Variable(pb),\n",
    "          'PC':tf.Variable(pc)}\n",
    "\n",
    "pi = tf.constant(np.pi, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get variables and weights for Hermite-Gauss Approximation\n",
    "\n",
    "Here we use 15 Hermite-Gauss nodes. They are placed symmetrically around zero. The 7 negative nodes are not used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_gauss,w_gauss = hermgauss(15)\n",
    "n_gauss = tf.constant(x_gauss.size, dtype=tf.int32)\n",
    "x_gauss = tf.constant(x_gauss, dtype=tf.float32)\n",
    "w_gauss = tf.constant(w_gauss, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load (u,lambda) data pairs in constant tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = tf.constant(rel_data['u'])\n",
    "lambdas = tf.constant(rel_data['Lambda'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of Likelihood function in TensorFlow\n",
    "\n",
    "The negative of the log-likelihood function is:\n",
    "\n",
    "$-\\mathcal{\\ln L}(\\theta)=-\\sum_{i}\\ln p_{\\lambda_{i}}(u_{i}|\\theta)=-\\sum_{i}\\ln [ e^{-\\lambda_{i}u_{i}} p_{0}(u_{i}|\\theta)/K(\\lambda_{i}|\\theta) ]$\n",
    "\n",
    "where $\\theta$ represents the parameters,\n",
    "\n",
    "$p_{0}(u)=p_{b}p_B(u) + p_{m}p_M(u)+p_{{\\rm c}}\\int_{\\tilde{u}_{C}}^{+\\infty}p_{WCA}(u')p_B(u-u')u'$\n",
    "\n",
    "$K(\\lambda)=K_{C}(\\lambda)K_{B}(\\lambda)$\n",
    "\n",
    "$K_{C}(\\lambda)= p_{b}+p_{m}e^{-\\lambda u_{{\\rm max}}}+p_{c}K_{WCA}(\\lambda)$\n",
    "\n",
    "$K{}_{WCA}(\\lambda)=\\int_{\\tilde{u}_{C}}^{u_{{\\rm max}}}p_{WCA}(u)e^{-\\lambda u}du$\n",
    "\n",
    "$K_{B}(\\lambda)=\\int_{-\\infty}^{+\\infty}p_{B}(u)e^{-\\lambda u}=e^{\\sigma_{B}^{2}\\lambda(\\lambda/2-\\bar{u}_{B}/\\sigma_{B}^{2})}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian mixture for B for all binding energies\n",
    "\n",
    "This computes $p_B(u)$ for all binding energy samples. In general $p_B(u)$ is a mixture of two (or more) Gaussians.\n",
    "\n",
    "gauss_bA = $\\frac{1}{\\sqrt{2\\pi}\\sigma_{BA}}e^{\\frac{-(u-u_{BA})^2}{2\\sigma_{BA}^2}}$ \n",
    "<br>\n",
    "gauss_bB = $\\frac{1}{\\sqrt{2\\pi}\\sigma_{BB}}e^{\\frac{-(u-u_{BB})^2}{2\\sigma_{BB}^2}}$ \n",
    "<br>\n",
    "gauss_b = $P_A *\\frac{1}{\\sqrt{2\\pi}\\sigma_{BA}}e^{\\frac{-(u-u_{BA})^2}{2\\sigma_{BA}^2}} + (1-P_A)*\\frac{1}{\\sqrt{2\\pi}\\sigma_{BB}}e^{\\frac{-(u-u_{BB})^2}{2\\sigma_{BB}^2}}$\n",
    "\n",
    "where $P_A$ and $P_B = 1 - P_A$ are the populations of the two conformational states at $\\lambda = 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(params,pi,u):\n",
    "    \n",
    "    gauss_bA = tf.exp(-tf.pow(u-params['UBA'],2)/(2.0*tf.pow(params['SIGBA'],2)))/(tf.sqrt(2.*pi)*params['SIGBA'])\n",
    "    gauss_bB = tf.exp(-tf.pow(u-params['UBB'],2)/(2.0*tf.pow(params['SIGBB'],2)))/(tf.sqrt(2.*pi)*params['SIGBB'])\n",
    "    gauss_b = params['PA']*gauss_bA + gauss_bB - params['PA']*gauss_bB\n",
    "    \n",
    "    return gauss_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian for energies at large distances where U -> u-umax where umax = $10^6/kT$\n",
    "\n",
    "this computes $p_M(u)$, which has the same form and parameters of $p_B(u)$ but is centered at $\\bar{u}_B + u_{\\rm max}$ \n",
    "\n",
    "gauss_bA_far = $\\frac{1}{\\sqrt{2\\pi}\\sigma_{BA}}e^{\\frac{-(U-u_{BA})^2}{2\\sigma_{BA}^2}}$ \n",
    "<br>\n",
    "gauss_bB_far = $\\frac{1}{\\sqrt{2\\pi}\\sigma_{BB}}e^{\\frac{-(U-u_{BB})^2}{2\\sigma_{BB}^2}}$ \n",
    "<br>\n",
    "gauss_b_far = $P_A *\\frac{1}{\\sqrt{2\\pi}\\sigma_{BA}}e^{\\frac{-(U-u_{BA})^2}{2\\sigma_{BA}^2}} + (1-P_A)*\\frac{1}{\\sqrt{2\\pi}\\sigma_{BB}}e^{\\frac{-(U-u_{BB})^2}{2\\sigma_{BB}^2}}$\n",
    "\n",
    "U is $u - u_{\\rm max}$ so the argument of each Gaussian is $u - (u_{\\rm max} +  \\bar{u}_B)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U = tf.constant(rel_data['U'])\n",
    "\n",
    "def gaussian_far(params,pi,U):\n",
    "    \n",
    "    gauss_bA_far = tf.exp(-tf.pow(U-params['UBA'],2)/(2.0*tf.pow(params['SIGBA'],2)))/(tf.sqrt(2.*pi)*params['SIGBA'])\n",
    "    gauss_bB_far = tf.exp(-tf.pow(U-params['UBB'],2)/(2.0*tf.pow(params['SIGBB'],2)))/(tf.sqrt(2.*pi)*params['SIGBB'])\n",
    "    gauss_b_far = params['PA']*gauss_bA_far + gauss_bB_far - params['PA']*gauss_bB_far\n",
    "    \n",
    "    return gauss_b_far"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution of gaussian (mixture) and pwca\n",
    "\n",
    "pwca = $n_L * \\left[1-\\frac{\\sqrt{1+\\hat{x}_c}}{\\sqrt{1+x}} \\right]^{n_L-1}*\\frac{Heaviside(u_c-\\hat{u}_c)\\sqrt{1+\\hat{x}_c}}{4\\epsilon_{LJ}x(1+x)^{3/2}}$ <br>\n",
    "where <br>\n",
    "$x = \\sqrt{u_c/\\epsilon_{LJ}}$ <br>\n",
    "$\\hat{x}_c = \\sqrt{\\hat{u}_c/\\epsilon_{LJ}}$\n",
    "\n",
    "#### Assuming statistical independence of the background and collisional energies, the probability density of the total binding energy is given by $P_0$ which is the convolution of their respective probability densities\n",
    "\n",
    "$p_0(u) = p_b p_B(u) + p_m p_M(u) + p_c \\int_{u_c}^\\infty p_{wca}(u')p_B(u-u')du'$\n",
    "\n",
    "`nm` is an approximation such that to the normalization factor of $p_{wca}$ between $u_C$ and $u_{\\rm max}$ is ${\\rm nm} \\times nl$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umax = 1.e6*beta\n",
    "pm = tf.constant(1. - pb - pc)\n",
    "xc = tf.sqrt(params['UC']/params['E'])\n",
    "a = tf.sqrt(1.+xc)\n",
    "eps = xc/10.\n",
    "xm = tf.sqrt(umax/params['E'])\n",
    "nm = tf.pow(1. - params['NL']*a/xm, -1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this performs the convolution. Once for each of the two states (A and B) of the mixture in $p_B(u)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss_b = gaussian(params,pi,u)\n",
    "gauss_b_far = gaussian_far(params,pi,U)\n",
    "sq2 = tf.sqrt(2.)\n",
    "\n",
    "def pwcaA(params,u,x_gauss,eps,nm):\n",
    "    \"\"\" Pwca for all input y's \"\"\"\n",
    "    sq2 = tf.sqrt(2.)\n",
    "    yA = sq2*params['SIGBA']*x_gauss + u[:,None] - params['UBA']\n",
    "    x1A = tf.pow(yA/params['E'],2) #to make x positive\n",
    "    xA  = tf.pow( x1A , 0.25 )\n",
    "    bA = tf.sqrt(1.+ xA)\n",
    "    z1A = tf.tanh( tf.pow(a/bA,12.) )\n",
    "    zA = tf.pow( z1A, 1./12. ) #caps z to 1\n",
    "    fcore2A = tf.pow((1.-zA), params['NL']-1.)\n",
    "    fcore3A = a/((xA+eps)*tf.pow(bA,3)*4.*params['E'])\n",
    "    fcore4A = tf.sigmoid(20.*(yA-0.5*params['UC'])/params['UC'])\n",
    "    pwcaA = nm*params['NL']*fcore2A*fcore3A*fcore4A\n",
    "    \n",
    "    return pwcaA\n",
    "#---\n",
    "pwca_A = pwcaA(params,u,x_gauss,eps,nm)\n",
    "qA = tf.matmul(pwca_A,tf.reshape(w_gauss,[n_gauss,1]))/tf.sqrt(pi)\n",
    "q2A = qA[:,0]\n",
    "\n",
    "def pwcaB(params,u,x_gauss,eps,nm):\n",
    "\n",
    "    yB = sq2*params['SIGBB']*x_gauss + u[:,None] - params['UBB']\n",
    "    x1B = tf.pow(yB/params['E'],2) #to make x positive\n",
    "    xB  = tf.pow( x1B , 0.25 )\n",
    "    bB = tf.sqrt(1.+ xB)\n",
    "    z1B = tf.tanh( tf.pow(a/bB,12.) )\n",
    "    zB = tf.pow( z1B, 1./12. ) #caps z to 1\n",
    "    fcore2B = tf.pow((1.-zB), params['NL']-1.)\n",
    "    fcore3B = a/((xB+eps)*tf.pow(bB,3)*4.*params['E'])\n",
    "    fcore4B = tf.sigmoid(20.*(yB-0.5*params['UC'])/params['UC'])\n",
    "    pwcaB = nm*params['NL']*fcore2B*fcore3B*fcore4B\n",
    "    \n",
    "    return pwcaB\n",
    "#---\n",
    "pwca_B = pwcaB(params,u,x_gauss,eps,nm)\n",
    "\n",
    "qB = tf.matmul(pwca_B,tf.reshape(w_gauss,[n_gauss,1]))/tf.sqrt(pi)\n",
    "q2B = qB[:,0]\n",
    "\n",
    "q2 = params['PA']*q2A + q2B - params['PA']*q2B\n",
    "\n",
    "#p0's\n",
    "p0 = params['PB']*gauss_b + params['PC']*q2 + pm*gauss_b_far\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model for the free energy profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is $K_{B}(\\lambda)=\\int_{-\\infty}^{+\\infty}p_{B}(u)e^{-\\lambda u}=e^{\\sigma_{B}^{2}\\lambda(\\lambda/2-\\bar{u}_{B}/\\sigma_{B}^{2})}$ but for the state mixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kB1\n",
    "klBA = tf.exp(0.5*tf.pow(params['SIGBA'],2)*tf.pow(lambdas,2) - lambdas*params['UBA'])\n",
    "klBB = tf.exp(0.5*tf.pow(params['SIGBB'],2)*tf.pow(lambdas,2) - lambdas*params['UBB']) \n",
    "klB1 = params['PA']*klBA + klBB - params['PA']*klBB\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this sets up an exponential grid to perform\n",
    "\n",
    "$K{}_{WCA}(\\lambda)=\\int_{\\tilde{u}_{C}}^{u_{{\\rm max}}}p_{WCA}(u)e^{-\\lambda u}du$\n",
    "\n",
    "`xasymp` is the actual grid ($x$), `dxasymp` is the grid spacing ($dx$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = uc*beta\n",
    "umax = 1.e6*beta\n",
    "ymax = np.log(umax)/a \n",
    "    \n",
    "def grid():\n",
    "    x_grid = {}\n",
    "    #a = uc*beta\n",
    "    #umax = 1.e6*beta\n",
    "    #ymax = np.log(umax)/a # \n",
    "    dy = ymax/100.0\n",
    "    xasymp = np.float32(np.exp(a*np.arange(0.,ymax,dy)) - 1.) + 1.e-6\n",
    "    dxasymp = np.float32(xasymp[1:] - xasymp[:-1])\n",
    "    xasymp = np.float32(xasymp[:-1])\n",
    "\n",
    "    x_grid['nx'] = tf.constant(dxasymp.size, dtype=tf.int32)\n",
    "    x_grid['xasymp'] = tf.constant(xasymp, dtype=tf.float32)\n",
    "    x_grid['dxasymp'] = tf.constant(dxasymp, dtype=tf.float32)\n",
    "    \n",
    "    return x_grid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this computes a modified $p_{wca}(u)$ over the integration grid to avoid the step function:\n",
    "\n",
    "$p_{WCA}(u_{C})\\simeq n_{l}\\left[1-\\tanh(z^{12})^{1/12}\\right]^{n_{l}-1}\\frac{s(u_{C}-\\tilde{u}_{C})}{4\\epsilon_{LJ}}\\frac{(1+x_{C})^{1/2}}{x(1+x)^{3/2}}$\n",
    "\n",
    "where $z=(1+x_{C})^{1/2}/(1+x)^{1/2}$ and $s(u)=[1+\\exp(-20u/\\tilde{u}_{C})]^{-1}$ is the sigmoid function.\n",
    "\n",
    "It then perform the integration for all possible $\\lambda$ values by computing a 2-D $\\exp(-\\lambda u)$ tensor and performing a matrix multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_grid = grid()\n",
    "def pwca_x(params,x_grid):\n",
    "    \"\"\" pwca for the x grid \"\"\"\n",
    "\n",
    "    x1_s = tf.pow(x_grid['xasymp']/params['E'],2) #to make x positive\n",
    "    x_s  = tf.pow( x1_s , 0.25 )\n",
    "    b_s = tf.sqrt(1.+ x_s)\n",
    "    z1_s = tf.tanh( tf.pow(a/b_s,12.) )\n",
    "    z_s = tf.pow( z1_s, 1./12. ) #caps z to 1\n",
    "    fcore2_s = tf.pow((1.-z_s), params['NL']-1.)\n",
    "    fcore3_s = a/((x_s+eps)*tf.pow(b_s,3)*4.*params['E'])\n",
    "    fcore4_s = tf.sigmoid(20.*(x_grid['xasymp']-0.5*params['UC'])/params['UC'])\n",
    "    pwca_s = nm*params['NL']*fcore2_s*fcore3_s*fcore4_s\n",
    "    \n",
    "    return pwca_s\n",
    "pwca_s = pwca_x(params,x_grid)\n",
    "\n",
    "def kwca(x_grid,pwca_s):\n",
    "    #kwca\n",
    "    fsamples = x_grid['dxasymp']*pwca_s\n",
    "    expl = tf.exp(- x_grid['xasymp'] * lambdas[:,None])\n",
    "    q_C = tf.matmul(expl,tf.reshape(fsamples,[x_grid['nx'],1]))\n",
    "    klwca = q_C[:,0]\n",
    "    return klwca\n",
    "\n",
    "klwca= kwca(x_grid,pwca_s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally it assembles $p_0(u)$ and $K(\\lambda)$ for each data point into the -log likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#free energies\n",
    "e2 = tf.exp(-1.e6*beta * lambdas)\n",
    "klC = params['PB'] + e2 - params['PC']*e2 - params['PB']*e2 + params['PC'] * klwca\n",
    "kl = klB1*klC\n",
    "pkl = p0/kl\n",
    "\n",
    "#cost function\n",
    "cost = -tf.reduce_sum(tf.log(pkl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize and start tensorflow optimizer session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(2.e-4)\n",
    "\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "gradient_cost = optimizer.compute_gradients(cost)\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(init)\n",
    "    ll = sess.run(cost)\n",
    "\n",
    "    best_loss = ll\n",
    "    best_ubA = sess.run(params['UBA'])\n",
    "    best_sbA = sess.run(params['SIGBA'])\n",
    "    best_ubB = sess.run(params['UBB'])\n",
    "    best_sbB = sess.run(params['SIGBB'])\n",
    "    best_pA = sess.run(params['PA'])\n",
    "    best_pb = sess.run(params['PB'])\n",
    "    best_pc = sess.run(params['PC'])\n",
    "    best_nl = sess.run(params['NL'])\n",
    "    best_elj = sess.run(params['E'])\n",
    "    best_uc = sess.run(params['UC'])   \n",
    "    for step in range(100):\n",
    "        sess.run(train)\n",
    "        ll = sess.run(cost)\n",
    "        lubA = sess.run(params['UBA'])\n",
    "        lsbA = sess.run(params['SIGBA'])\n",
    "        lubB = sess.run(params['UBB'])\n",
    "        lsbB = sess.run(params['SIGBB'])\n",
    "        lpA =  sess.run(params['PA'])\n",
    "        lpb = sess.run(params['PB'])\n",
    "        lpc = sess.run(params['PC'])\n",
    "        lnl = sess.run(params['NL'])\n",
    "        lelj = sess.run(params['E'])\n",
    "        luc = sess.run(params['UC'])                     \n",
    "        if( ll < best_loss ):\n",
    "            best_loss = ll\n",
    "            best_ubA = lubA\n",
    "            best_sbA = lsbA\n",
    "            best_ubB = lubB\n",
    "            best_sbB = lsbB\n",
    "            best_pA = lpA\n",
    "            best_pb = lpb\n",
    "            best_pc = lpc\n",
    "            best_nl = lnl\n",
    "            best_elj = lelj\n",
    "            best_uc = luc\n",
    "      \n",
    "        df_params = df_params.append({'step':step,'uBA':lubA*kT,'sbA':lsbA*kT,\n",
    "                                           'uBB':lubB*kT,'sbB':lsbB*kT,'pA':lpA,'pb':lpb,\n",
    "                                           'pc':lpc,'pm':1.0-pb-pc,'umax':umax,'nl':lnl,'eLJ':lelj*kT,\n",
    "                                           'uc':luc*kT,'cost':ll},ignore_index=True)\n",
    "\n",
    "    print(\"----- End of optimization --------\");\n",
    "    print(\"best\", \"x:\", \" uBA =\", best_ubA*kT, \"sbA =\", best_sbA*kT, \"uBB =\", best_ubB*kT, \"sbB =\", best_sbB*kT, \"pA =\", best_pA, \"pb = \", best_pb, \"pc =\", best_pc, \"pm = \", 1.0-pb-pc, \"umax = \", umax, \"nl = \", best_nl, \"eLJ = \", best_elj*kT, \"uc = \", best_uc*kT, \"cost =\", best_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_params.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_params.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_params.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cost = df_params[['step','cost']]\n",
    "df_cost.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "ax0 = fig.add_subplot(221)\n",
    "ax1 = fig.add_subplot(222)\n",
    "ax2 = fig.add_subplot(223)\n",
    "ax3 = fig.add_subplot(224)\n",
    "\n",
    "# 1st plot\n",
    "df_params.plot(kind='line',x='step',y='cost', figsize=(20,10),ax=ax0)\n",
    "ax0.set_ylabel(\"Cost\")\n",
    "ax0.set_xlabel(\"Steps\")\n",
    "\n",
    "# 2nd plot\n",
    "df_params.plot(kind='line',x='step',y='nl',figsize=(20,10),ax=ax1)\n",
    "ax1.set_ylabel(\"NL\")\n",
    "ax1.set_xlabel(\"Steps\")\n",
    "\n",
    "# 3rd plot\n",
    "df_params.plot(kind='line',x='step',y='pb',figsize=(20,10),ax=ax2)\n",
    "ax2.set_ylabel(\"PB\")\n",
    "ax2.set_xlabel(\"Steps\")\n",
    "\n",
    "# 4th plot\n",
    "df_params.plot(kind='line',x='step',y='pc',figsize=(20,10),ax=ax3)\n",
    "ax3.set_ylabel(\"PC\")\n",
    "ax3.set_xlabel(\"Steps\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_parameters = ['step', 'uBA','sbA','uBB','sbB','pA','pb','pc', 'pm','umax','nl',\n",
    "                 'eLJ','uc','cost']\n",
    "df_params = pd.DataFrame(columns = tf_parameters)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(2.e-4)\n",
    "\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "gradient_cost = optimizer.compute_gradients(cost)\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(init)\n",
    "    ll = sess.run(cost)\n",
    "\n",
    "    best_loss = ll\n",
    "    best_ubA = sess.run(params['UBA'])\n",
    "    best_sbA = sess.run(params['SIGBA'])\n",
    "    best_ubB = sess.run(params['UBB'])\n",
    "    best_sbB = sess.run(params['SIGBB'])\n",
    "    best_pA = sess.run(params['PA'])\n",
    "    best_pb = sess.run(params['PB'])\n",
    "    best_pc = sess.run(params['PC'])\n",
    "    best_nl = sess.run(params['NL'])\n",
    "    best_elj = sess.run(params['E'])\n",
    "    best_uc = sess.run(params['UC'])   \n",
    "    for step in range(200):\n",
    "        sess.run(train)\n",
    "        ll = sess.run(cost)\n",
    "        lubA = sess.run(params['UBA'])\n",
    "        lsbA = sess.run(params['SIGBA'])\n",
    "        lubB = sess.run(params['UBB'])\n",
    "        lsbB = sess.run(params['SIGBB'])\n",
    "        lpA =  sess.run(params['PA'])\n",
    "        lpb = sess.run(params['PB'])\n",
    "        lpc = sess.run(params['PC'])\n",
    "        lnl = sess.run(params['NL'])\n",
    "        lelj = sess.run(params['E'])\n",
    "        luc = sess.run(params['UC'])                     \n",
    "        if( ll < best_loss ):\n",
    "            best_loss = ll\n",
    "            best_ubA = lubA\n",
    "            best_sbA = lsbA\n",
    "            best_ubB = lubB\n",
    "            best_sbB = lsbB\n",
    "            best_pA = lpA\n",
    "            best_pb = lpb\n",
    "            best_pc = lpc\n",
    "            best_nl = lnl\n",
    "            best_elj = lelj\n",
    "            best_uc = luc\n",
    "      \n",
    "        df_params = df_params.append({'step':step,'uBA':lubA*kT,'sbA':lsbA*kT,\n",
    "                                           'uBB':lubB*kT,'sbB':lsbB*kT,'pA':lpA,'pb':lpb,\n",
    "                                           'pc':lpc,'pm':1.0-pb-pc,'umax':umax,'nl':lnl,'eLJ':lelj*kT,\n",
    "                                           'uc':luc*kT,'cost':ll},ignore_index=True)\n",
    "\n",
    "    print(\"----- End of optimization --------\");\n",
    "    print(\"best\", \"x:\", \" uBA =\", best_ubA*kT, \"sbA =\", best_sbA*kT, \"uBB =\", best_ubB*kT, \"sbB =\", best_sbB*kT, \"pA =\", best_pA, \"pb = \", best_pb, \"pc =\", best_pc, \"pm = \", 1.0-pb-pc, \"umax = \", umax, \"nl = \", best_nl, \"eLJ = \", best_elj*kT, \"uc = \", best_uc*kT, \"cost =\", best_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "ax0 = fig.add_subplot(221)\n",
    "ax1 = fig.add_subplot(222)\n",
    "ax2 = fig.add_subplot(223)\n",
    "ax3 = fig.add_subplot(224)\n",
    "\n",
    "# 1st plot\n",
    "df_params.plot(kind='line',x='step',y='cost', figsize=(20,10),ax=ax0)\n",
    "ax0.set_ylabel(\"Cost\")\n",
    "ax0.set_xlabel(\"Steps\")\n",
    "\n",
    "# 2nd plot\n",
    "df_params.plot(kind='line',x='step',y='nl',figsize=(20,10),ax=ax1)\n",
    "ax1.set_ylabel(\"NL\")\n",
    "ax1.set_xlabel(\"Steps\")\n",
    "\n",
    "# 3rd plot\n",
    "df_params.plot(kind='line',x='step',y='pb',figsize=(20,10),ax=ax2)\n",
    "ax2.set_ylabel(\"PB\")\n",
    "ax2.set_xlabel(\"Steps\")\n",
    "\n",
    "# 4th plot\n",
    "df_params.plot(kind='line',x='step',y='pc',figsize=(20,10),ax=ax3)\n",
    "ax3.set_ylabel(\"PC\")\n",
    "ax3.set_xlabel(\"Steps\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_parameters = ['step', 'uBA','sbA','uBB','sbB','pA','pb','pc', 'pm','umax','nl',\n",
    "                 'eLJ','uc','cost']\n",
    "df_params = pd.DataFrame(columns = tf_parameters)\n",
    "\n",
    "var_list1 = [params['PC'],params['PB'],params['NL']]\n",
    "\n",
    "\n",
    "## .minimize combines compute_gradients and apply_gradients\n",
    "\n",
    "opt = tf.train.AdamOptimizer(learning_rate=2.e-4)\n",
    "grads_and_vars = opt.compute_gradients(cost, var_list=var_list1)\n",
    "nl_grad,_ = grads_and_vars[2]\n",
    "train_op = opt.apply_gradients([grads_and_vars[0],grads_and_vars[1],(nl_grad*2.e5,params['NL'])])\n",
    "######\n",
    "\n",
    "#optimizer = tf.train.AdamOptimizer(2.e-4)\n",
    "#train = optimizer.minimize(cost, var_list=var_list1)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "#gradient_cost = optimizer.compute_gradients(cost)\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(init)\n",
    "    ll = sess.run(cost)\n",
    "\n",
    "    best_loss = ll\n",
    "    best_ubA = sess.run(params['UBA'])\n",
    "    best_sbA = sess.run(params['SIGBA'])\n",
    "    best_ubB = sess.run(params['UBB'])\n",
    "    best_sbB = sess.run(params['SIGBB'])\n",
    "    best_pA = sess.run(params['PA'])\n",
    "    best_pb = sess.run(params['PB'])\n",
    "    best_pc = sess.run(params['PC'])\n",
    "    best_nl = sess.run(params['NL'])\n",
    "    best_elj = sess.run(params['E'])\n",
    "    best_uc = sess.run(params['UC'])   \n",
    "    for step in range(300):\n",
    "        sess.run(train_op)\n",
    "        ll = sess.run(cost)\n",
    "        lubA = sess.run(params['UBA'])\n",
    "        lsbA = sess.run(params['SIGBA'])\n",
    "        lubB = sess.run(params['UBB'])\n",
    "        lsbB = sess.run(params['SIGBB'])\n",
    "        lpA =  sess.run(params['PA'])\n",
    "        lpb = sess.run(params['PB'])\n",
    "        lpc = sess.run(params['PC'])\n",
    "        lnl = sess.run(params['NL'])\n",
    "        lelj = sess.run(params['E'])\n",
    "        luc = sess.run(params['UC'])                     \n",
    "        if( ll < best_loss ):\n",
    "            best_loss = ll\n",
    "            best_ubA = lubA\n",
    "            best_sbA = lsbA\n",
    "            best_ubB = lubB\n",
    "            best_sbB = lsbB\n",
    "            best_pA = lpA\n",
    "            best_pb = lpb\n",
    "            best_pc = lpc\n",
    "            best_nl = lnl\n",
    "            best_elj = lelj\n",
    "            best_uc = luc\n",
    "      \n",
    "        df_params = df_params.append({'step':step,'uBA':lubA*kT,'sbA':lsbA*kT,\n",
    "                                           'uBB':lubB*kT,'sbB':lsbB*kT,'pA':lpA,'pb':lpb,\n",
    "                                           'pc':lpc,'pm':1.0-pb-pc,'umax':umax,'nl':lnl,'eLJ':lelj*kT,\n",
    "                                           'uc':luc*kT,'cost':ll},ignore_index=True)\n",
    "\n",
    "    print(\"----- End of optimization --------\");\n",
    "    print(\"best\", \"x:\", \" uBA =\", best_ubA*kT, \"sbA =\", best_sbA*kT, \"uBB =\", best_ubB*kT, \"sbB =\", best_sbB*kT, \"pA =\", best_pA, \"pb = \", best_pb, \"pc =\", best_pc, \"pm = \", 1.0-pb-pc, \"umax = \", umax, \"nl = \", best_nl, \"eLJ = \", best_elj*kT, \"uc = \", best_uc*kT, \"cost =\", best_loss)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "ax0 = fig.add_subplot(221)\n",
    "ax1 = fig.add_subplot(222)\n",
    "ax2 = fig.add_subplot(223)\n",
    "ax3 = fig.add_subplot(224)\n",
    "\n",
    "# 1st plot\n",
    "df_params.plot(kind='line',x='step',y='cost', figsize=(20,10),ax=ax0)\n",
    "ax0.set_ylabel(\"Cost\")\n",
    "ax0.set_xlabel(\"Steps\")\n",
    "\n",
    "# 2nd plot\n",
    "df_params.plot(kind='line',x='step',y='nl',figsize=(20,10),ax=ax1)\n",
    "ax1.set_ylabel(\"NL\")\n",
    "ax1.set_xlabel(\"Steps\")\n",
    "\n",
    "# 3rd plot\n",
    "df_params.plot(kind='line',x='step',y='pb',figsize=(20,10),ax=ax2)\n",
    "ax2.set_ylabel(\"PB\")\n",
    "ax2.set_xlabel(\"Steps\")\n",
    "\n",
    "# 4th plot\n",
    "df_params.plot(kind='line',x='step',y='pc',figsize=(20,10),ax=ax3)\n",
    "ax3.set_ylabel(\"PC\")\n",
    "ax3.set_xlabel(\"Steps\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
